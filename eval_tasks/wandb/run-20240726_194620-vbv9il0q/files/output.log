
[34m[1mwandb[39m[22m:   1 of 1 files downloaded.
[34m[1mwandb[39m[22m:   1 of 1 files downloaded.
Traceback (most recent call last):
  File "/home/ubuntu/miniconda3/envs/new_env/lib/python3.10/site-packages/transformers/utils/hub.py", line 402, in cached_file
    resolved_file = hf_hub_download(
  File "/home/ubuntu/miniconda3/envs/new_env/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py", line 101, in inner_f
    return f(*args, **kwargs)
  File "/home/ubuntu/miniconda3/envs/new_env/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
    validate_repo_id(arg_value)
  File "/home/ubuntu/miniconda3/envs/new_env/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
    raise HFValidationError(
huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/home/ubuntu/evol-merge/final_merge/'. Use `repo_type` argument if needed.
The above exception was the direct cause of the following exception:
Traceback (most recent call last):
  File "/home/ubuntu/evo-merge/eval_tasks/run_jmtbench_eval.py", line 63, in <module>
    mtbench_evaluate()
  File "/home/ubuntu/evo-merge/eval_tasks/mtbench_eval.py", line 95, in mtbench_evaluate
    run_eval(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/fastchat/llm_judge/gen_model_answer.py", line 60, in run_eval
    get_answers_func(
  File "/home/ubuntu/miniconda3/envs/new_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/fastchat/llm_judge/gen_model_answer.py", line 104, in get_model_answers
    tokenizer: PreTrainedTokenizerBase = AutoTokenizer.from_pretrained(
  File "/home/ubuntu/miniconda3/envs/new_env/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py", line 833, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
  File "/home/ubuntu/miniconda3/envs/new_env/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py", line 665, in get_tokenizer_config
    resolved_config_file = cached_file(
  File "/home/ubuntu/miniconda3/envs/new_env/lib/python3.10/site-packages/transformers/utils/hub.py", line 466, in cached_file
    raise EnvironmentError(
OSError: Incorrect path_or_model_id: '/home/ubuntu/evol-merge/final_merge/'. Please provide either the path to a local folder or the repo_id of a model on the Hub.